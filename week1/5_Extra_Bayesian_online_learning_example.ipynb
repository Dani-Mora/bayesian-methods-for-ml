{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Online learning\n",
    "\n",
    "In this notebook we are providing an example on how to use the Bayesian framework for inference using an online fashion. We show that, in order to train on a data stream, we do not need to store all data but the parameters of the posterior at each iteration update."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import scipy.stats\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import gif\n",
    "\n",
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use case: classic toin coss\n",
    "\n",
    "We want to estimate the probability of getting heads for a specific coin. At each iteration we will flip the coin $n$ times and update the posterior probability. We will be using a fake coin that produces heads around 20% of the times.\n",
    "\n",
    "The likelihood of each iteration is a Binomial distribution. Given that, for discrete outcomes, the beta distribution is a conjugate of the Binomial likelihood, the posterior is also a Beta distribution. We use the posterior of one iteration as the prior of the next one.\n",
    "\n",
    "## Summary\n",
    "\n",
    "- Prior $P(\\theta) = P(p) \\sim Beta(a, b)$\n",
    "- Likelihood $P(X|\\theta) = P(X|p) \\sim Binomial(n, k, p)$\n",
    "- Posterior $P(\\theta|X) = P(p|X) \\sim Beta(a', b')$\n",
    "\n",
    "Given the outcomes of $i$th experiment $X_i = \\{x_1, x_2, \\ldots, x_n\\}$, the parameters of the posterior $a'$, $b'$ are calculated as:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "a' & = a + \\sum x_i \\\\\n",
    "b' & = b + n - \\sum x_i\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "More information in the conjugate prior table in the [Wikipedia page](https://en.wikipedia.org/wiki/Conjugate_prior)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define groundtruth values and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Beta:\n",
    "    \n",
    "    alpha: float\n",
    "    beta: float\n",
    "\n",
    "real_p = 0.20\n",
    "\n",
    "samples_per_step = 10\n",
    "\n",
    "# Assume coin is fair\n",
    "initial_prior_params = Beta(alpha=2, beta=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement coin toss logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Tosses:\n",
    "    \n",
    "    values: np.ndarray\n",
    "    \n",
    "    @staticmethod\n",
    "    def sample(p: float, n: int) -> np.ndarray:\n",
    "        return Tosses(\n",
    "            values=scipy.stats.bernoulli.rvs(p=p, size=n)\n",
    "        )\n",
    "\n",
    "    def heads(self) -> int:\n",
    "        return (self.values == 1).sum()\n",
    "    \n",
    "    def tails(self) -> int:\n",
    "        return (self.values == 0).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_TRIALS = 250\n",
    "\n",
    "\n",
    "@gif.frame\n",
    "def plot(prior_fn: callable,\n",
    "         posterior_fn: callable,\n",
    "         likelihood_fn: callable,\n",
    "         i: int) -> None:\n",
    "\n",
    "    # Init plot\n",
    "    fig = plt.figure(figsize=(12, 4))\n",
    "    ax = fig.gca()\n",
    "    ax2 = ax.twinx()\n",
    "    xs = np.linspace(0, 1, 500)\n",
    "\n",
    "    ax.plot(xs, prior_fn(xs), label='prior')\n",
    "    ax.plot(xs, posterior_fn(xs), label='posterior')\n",
    "    ax.set_ylabel('probability density function')\n",
    "    \n",
    "    # Show likelihood in another axis (since it is not a prob dist)\n",
    "    ax2.plot(xs, likelihood_fn(xs), label='likelihood', color='green')\n",
    "    ax2.set_ylabel('likelihood value')\n",
    "    \n",
    "    # Show legend and title\n",
    "    ax.legend(loc=2)\n",
    "    ax2.legend(loc=1)\n",
    "    ax.set_title(f'Iteration: {i}')\n",
    "\n",
    "\n",
    "animation_path = os.path.join('media', 'conjugates.gif')\n",
    "\n",
    "# Create animation if does not exist\n",
    "if not os.path.isfile(animation_path):\n",
    "\n",
    "    frames = []\n",
    "    for i in range(N_TRIALS):\n",
    "\n",
    "        if i == 0:\n",
    "            prior_params = initial_prior_params\n",
    "        else:\n",
    "            prior_params = posterior_params\n",
    "\n",
    "        # Get new observation\n",
    "        tosses = Tosses.sample(n=samples_per_step, p=real_p)\n",
    "\n",
    "        # Define Beta prior using parameters\n",
    "        prior_fn = scipy.stats.beta(a=prior_params.alpha,\n",
    "                                    b=prior_params.beta).pdf\n",
    "\n",
    "        # Likelihodd as PMF of binomial given data\n",
    "        likelihood_fn = lambda p: \\\n",
    "            scipy.stats.binom.pmf(n=samples_per_step, k=tosses.heads(), p=p)\n",
    "\n",
    "        # Posterior is Beta as Beta is the conjugate of the Binomial\n",
    "        posterior_params = Beta(alpha=tosses.heads() + prior_params.alpha,\n",
    "                                beta=tosses.tails() + prior_params.beta)\n",
    "        posterior_fn = scipy.stats.beta(a=posterior_params.alpha,\n",
    "                                        b=posterior_params.beta).pdf\n",
    "\n",
    "        # Generate plot for current step\n",
    "        frames.append(plot(prior_fn, posterior_fn, likelihood_fn, i))\n",
    "\n",
    "    gif.save(frames, animation_path, duration=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note we have reduced the size of the GIF so it is suitable for Github."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![SegmentLocal](media/conjugates.gif )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see the posterior probability successively approaches to the real value of $0.20$."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
